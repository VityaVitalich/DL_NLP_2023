{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Нейросети и PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## План\n",
    "1. Готовим обучение\n",
    "    1. Данные: `Dataset` & `DataLoader` \n",
    "    2. Модель: `nn.Module`\n",
    "    3. Рутина: все остальное\n",
    "2. Учим\n",
    "    1. Baseline\n",
    "    2. Stack more layers\n",
    "3. I/O\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Готовим обучение "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общий подход к решению задачи на pytorch такой:\n",
    "1. Подготовить данные, реализовать (или использовать готовый) класс `Dataset`, наследуясь от `torch.utils.data.Dataset`, обернуть его в `torch.utils.data.DataLoader`.\n",
    "2. Реализовать (или взять ±готовую) модель, наследуясь от `torch.nn.Module`.\n",
    "3. Приготовить оптимизатор для весов модели (из `torch.optim` или свой) и лосс\n",
    "4. Написать код для рутины обучения, включающий обработку данных из `DataLoader`, прогон их через модель, вычисление лосса и обновление весов оптимизатором."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Данные: `Dataset` & `DataLoader`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Tutorial @ pytorch.org](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n",
    "\n",
    "Класс датасета предоставит нам интерфейс к данным:\n",
    "* Метод `__getitem__(self, i)` позволяет получить `i`-й элемент обучающей выборки, обычно пару (data, label).\n",
    "    * Также обязательным является определение метода `__len__(self)`.\n",
    "* Можно сделать так, чтобы экземпляр класса датасета просто возвращал исходные данные, а можно (нужно) добавить в него аугментирование данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Dataset` - абстрактный класс, его нельзя использовать напрямую, а только через наследование:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset()\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим датасет поверх игрушечных данных с прошлого семинара:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "_a = np.random.uniform(1, 5)\n",
    "_b = np.random.uniform(-3, 3)\n",
    "_c = np.random.uniform(-3, 3)\n",
    "\n",
    "num_samples = 1000\n",
    "\n",
    "xs = np.random.uniform(-3, 3, size=num_samples)\n",
    "ys_clean = _a * xs ** 2 + _b * xs + _c\n",
    "ys_noise = np.random.normal(0, 1, size=len(ys_clean))\n",
    "ys = ys_clean + ys_noise\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.scatter(xs, ys, label=\"gt\", s=5)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, xs, ys):\n",
    "        super().__init__()\n",
    "        \n",
    "        if len(xs) != len(ys):\n",
    "            raise ValueError(f\"lens mismatch: {len(xs)} != {len(ys)}\")\n",
    "            \n",
    "        self.xs = xs\n",
    "        self.ys = ys\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.xs)\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        return (self.xs[i], self.ys[i])\n",
    "    \n",
    "    @staticmethod\n",
    "    def collate_fn(items_list):\n",
    "        xs = torch.zeros(len(items_list), 1)\n",
    "        ys = torch.zeros(len(items_list), 1)\n",
    "\n",
    "        for i, (x, y) in enumerate(items_list):\n",
    "            xs[i] = x\n",
    "            ys[i] = y\n",
    "\n",
    "        return xs, ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод `collate_fn` нужен не столько для самого датасета, сколько для оборачивания его в `DataLoader` - об этом чуть ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(xs, ys)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По датасету можно итерироваться (но вам это вряд ли будет нужно часто):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in dataset:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теоретически, для обучения достаточно уже объекта типа `Dataset`. Однако, для удобства и для автоматизации процессов перемешивания данных, формирования батчей и использования многопоточности есть удобный класс `DataLoader`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    drop_last=True, \n",
    "    collate_fn=dataset.collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Длина\" даталоадера - это количество батчей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К даталоадеру нельзя обращаться по индексу, но можно итерироваться по нему:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataloader:\n",
    "    xs, ys = batch\n",
    "    print(xs.shape, ys.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как именно происходит сборка батчей, покажем, реализовав свой игрушечный даталоадер с аналогичным функционалом:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**:\n",
    "Реализовать метод `__getitem__(self, i)`, который должен возвращать i-й батч. \n",
    "* Батч должен быть списком с числом элементов = равным числу элементов, возвращаемых датасетом при обращении по индексу (обычно 2 - данные и лейблы, но есть варианты).\n",
    "    * Каждый из элементов содержит не отдельный объект, а склеенный из отдельных объектов тензов\n",
    "    * Длина каждого = `batch_size`\n",
    "* Для сборки батча из отдельных элементов датасета используйте метод `self.dataset.collate_fn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataLoader:\n",
    "    \n",
    "    def __init__(self, dataset, batch_size, collate_fn):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.collate_fn = collate_fn\n",
    "        \n",
    "        self.indices = np.arange(len(dataset))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(dataset) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        # indices = ...\n",
    "        # items = ...\n",
    "        # batch = ...\n",
    "        \n",
    "        # END OF YOUR CODE\n",
    "        \n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataloader = MyDataLoader(dataset, batch_size=32, collate_fn=dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = my_dataloader[0]\n",
    "\n",
    "assert len(batch) == 2\n",
    "assert batch[0].shape == (32, 1)\n",
    "assert batch[1].shape == (32, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Про параметры `DataLoader`-а, которые мы сегодня не трогали (`pin_memory`, `num_workers`, ...), поговорим в другой раз."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.2. Модель: `nn.Module`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нейросетевые модели состоят из слоев, которые применяются ко входу (обычно) последовательно.\n",
    "Каждый слой должен быть наследником `torch.nn.Module`, чтобы сам pytorch понимал: перед ним слой нейросети, у него есть параметры, его надо уметь дифференцировать, и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание:**\n",
    "Реализовать недостающие куски кода в методах `__init__()` и `forward()`.\n",
    "* В `__init__()` должны быть инициализированы матрица `self.weights` (`out_dim x in_dim`) и вектор `bias` (или `None`).\n",
    "* В `forward()` они должны быть применены ко входу `x` (`batch x in_dim`).\n",
    "\n",
    "**NB**: Помните, что обычно обработка данных моделью происходит по батчам, т.е. даже если на вход придет 1 объект, у него будет размерность (`batch x in_dim`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLinear(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        self.bias = ...\n",
    "        self.weights = ...\n",
    "        \n",
    "        # END OF YOUR CODE\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        \n",
    "        # END OF YOUR CODE\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"CustomLinear({self.weights.shape[1]}, {self.weights.shape[0]}, bias={self.bias is not None})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = CustomLinear(8, 1)\n",
    "\n",
    "assert isinstance(linear.weights, torch.nn.Parameter)\n",
    "assert isinstance(linear.bias, torch.nn.Parameter)\n",
    "assert linear.weights.shape == (1, 8)\n",
    "assert linear.bias.shape == (1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, какие атрибуты и методы есть у нашего класса при наследовании от `nn.Module`.\n",
    "\n",
    "Во-первых, доступ к обучаемым (и не только) параметрам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in linear.parameters():\n",
    "    print(p)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in linear.named_parameters():\n",
    "    print(p)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для удобства чтения и отладки, часто полезно определить метод `__repr__()` для информативного вывода самого объекта:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важными полями являются индикатор `.training`: он показывает, в каком режиме находится модель - обучения или инференса.\n",
    "\n",
    "**Вопрос**: зачем?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.eval()\n",
    "linear.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.train()\n",
    "linear.training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB**: Выход из режима `training` не отключает вычисление градиентов!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы уже говорили в прошлый раз, вычисления можно производить не только в одиночной точности; для этого необходимо (но не всегда достаточно) привести все веса к соответствующему типу. Наследование от класса `nn.Module` позволяет сделать это одной командой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.weights.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = linear.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.weights.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = linear.float()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "linear.weights.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот что pytorch из коробки делать не позволяет, так это узнать, на каком устройстве лежит наша модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = linear.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.weights.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем собственно применить нашу модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(32, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = linear(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(32, 9)\n",
    "y = linear(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Рутина: все остальное"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1. Оптимизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(linear.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.param_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2. Лосс"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно написать самому:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(y_true, y_pred):\n",
    "    return ((y_true - y_pred) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys_true = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_pred = torch.randn_like(ys_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss(ys_true, ys_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно использовать готовые:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import mse_loss as torch_mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_mse_loss(ys_true, ys_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.3. Рутина обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание:** Дописать функцию для обучения.\n",
    "* Получение предсказаний моделью для объектов из батча\n",
    "* Подсчет лосса\n",
    "* Обновление весов по вызова backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, loss_fn, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    losses = []\n",
    "    for batch in dataloader:\n",
    "        xs, ys_true = batch\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        # ...\n",
    "        # ...\n",
    "        \n",
    "        # END OF YOUR CODE\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На валидации будем еще и сохранять результат предсказаний - для визуализации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_epoch(model, dataloader, loss_fn):\n",
    "    model.eval()\n",
    "    \n",
    "    losses = []\n",
    "    preds = []\n",
    "    for batch in dataloader:\n",
    "        xs, ys_true = batch\n",
    "        with torch.no_grad():\n",
    "            ys_pred = model(xs)\n",
    "        \n",
    "        loss = loss_fn(ys_pred, ys_true)        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        preds.append(ys_pred.numpy())\n",
    "    \n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    return np.mean(losses), preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Учим"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с обучения 1 полносвязного слоя, по сути - аппроксимируем данные прямой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 128\n",
    "lr = 8e-4\n",
    "batch_size = 8\n",
    "\n",
    "train_size = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.random.uniform(-3, 3, size=num_samples)\n",
    "ys_clean = _a * xs ** 2 + _b * xs + _c\n",
    "ys_noise = np.random.normal(0, 1, size=len(ys_clean))\n",
    "ys = ys_clean + ys_noise\n",
    "\n",
    "train_dataset = CustomDataset(xs[:train_size], ys[:train_size])\n",
    "val_dataset = CustomDataset(xs[train_size:], ys[train_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    collate_fn=train_dataset.collate_fn, \n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    collate_fn=train_dataset.collate_fn, \n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomLinear(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "val_losses = []\n",
    "val_preds = []\n",
    "for epoch in tqdm.trange(num_epochs):\n",
    "    loss = train_epoch(model, train_dataloader, optimizer, loss_fn, epoch)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    val_loss, preds = val_epoch(model, val_dataloader, loss_fn)\n",
    "    val_losses.append(val_loss)\n",
    "    val_preds.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(losses)\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_losses)\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"val loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.scatter(xs[train_size:], ys[train_size:], label=\"true\")\n",
    "plt.scatter(xs[train_size:], val_preds[-1], label=\"fc_1layer\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_1layer_train_losses = losses\n",
    "fc_1layer_val_losses = val_losses\n",
    "fc_1layer_preds = preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Stack more layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Sequential\n",
    "from torch.nn import ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: соберите сеть из двух полносвязных слоев размерами (1, 4) и (4, 1); добавьте между слоями нелинейность ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MegaModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = torch.nn.Sequential(\n",
    "            CustomLinear(in_dim, hidden_dim),\n",
    "            ReLU(),\n",
    "            CustomLinear(hidden_dim, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "model = ...\n",
    "# END OF YOUR CODE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "val_losses = []\n",
    "val_preds = []\n",
    "for epoch in tqdm.trange(num_epochs):\n",
    "    loss = train_epoch(model, train_dataloader, optimizer, loss_fn, epoch)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    val_loss, preds = val_epoch(model, val_dataloader, loss_fn)\n",
    "    val_losses.append(val_loss)\n",
    "    val_preds.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(losses, label=\"fc_2layers_4h\")\n",
    "plt.plot(fc_1layer_train_losses, label=\"fc_1layer\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_losses, label=\"fc_2layers_4h\")\n",
    "plt.plot(fc_1layer_val_losses, label=\"fc_1layer\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"val loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.scatter(xs[train_size:], ys[train_size:], label=\"true\")\n",
    "plt.scatter(xs[train_size:], val_preds[-1], label=\"fc_2layer_4h\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_2layer_4h_train_losses = losses\n",
    "fc_2layer_4h_val_losses = val_losses\n",
    "fc_2layer_4h_preds = preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим нейронов в скрытый слой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = MegaModel(1, 8, 1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "val_losses = []\n",
    "for epoch in tqdm.trange(num_epochs):\n",
    "    loss = train_epoch(model, train_dataloader, optimizer, loss_fn, epoch)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    val_loss, preds = val_epoch(model, val_dataloader, loss_fn)\n",
    "    val_losses.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(losses, label=\"fc_2layer_8h\")\n",
    "plt.plot(fc_2layer_4h_train_losses, label=\"fc_2layer_4h\")\n",
    "plt.plot(fc_1layer_train_losses, label=\"fc_1layer\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_losses, label=\"fc_2layer_8h\")\n",
    "plt.plot(fc_2layer_4h_val_losses, label=\"fc_2layer_4h\")\n",
    "plt.plot(fc_1layer_val_losses, label=\"fc_1layer\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"val loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.scatter(xs[train_size:], ys[train_size:], label=\"true\")\n",
    "plt.scatter(xs[train_size:], preds, label=\"fc_2layer_8h\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видимо, что наша модель ведет себя как кусочно-линейная функция. Любопытные визуализации на эту тему можно найти, например, [здесь](http://neuralnetworksanddeeplearning.com/chap4.htmlhttp://neuralnetworksanddeeplearning.com/chap4.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обученные веса модели хорошо бы уметь сохранять и загружать для дальнейшего использования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В Pytorch сохранение и загрузка весов выполняется через `state_dict` модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_fn = \"./state_dict.pth.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_fn, \"wb\") as fp:\n",
    "    torch.save(model.state_dict(), fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MegaModel(1,8,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_fn, \"rb\") as fp:\n",
    "    state_dict = torch.load(fp, map_location=\"cpu\")\n",
    "state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помимо непосредственно весов, бывает полезно сохранить и состояние других объектов: например, оптимизатора (чтобы продолжить обучении с той же точки):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, output_fn):\n",
    "    checkpoint = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict()\n",
    "    }\n",
    "    \n",
    "    with open(output_fn, \"wb\") as fp:\n",
    "        torch.save(checkpoint, output_fn)\n",
    "        \n",
    "def load_checkpoint(checkpoint_fn, model, optimizer):\n",
    "    with open(checkpoint_fn, \"rb\") as fp:\n",
    "        checkpoint = torch.load(fp, map_location=\"cpu\")\n",
    "    \n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "optimizer.param_groups[0][\"lr\"] = 1e-10\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_fn = \"./checkpoint.pth.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint(model, optimizer, checkpoint_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_checkpoint(checkpoint_fn, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNmX+t/f/S/AKgjzKepbc+b",
   "name": "Семинар 03. NN with PyTorch(Classwork).ipynb",
   "provenance": [
    {
     "file_id": "1VR8KlyfZEYXayf1AGBMwf2TB_k8HwedF",
     "timestamp": 1632410238934
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
